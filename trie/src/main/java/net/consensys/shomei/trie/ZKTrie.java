/*
 * Copyright ConsenSys Software Inc., 2023
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
 * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
 * specific language governing permissions and limitations under the License.
 */

package net.consensys.shomei.trie;

import static com.google.common.base.Preconditions.checkArgument;

import net.consensys.shomei.trie.StoredSparseMerkleTrie.GetAndProve;
import net.consensys.shomei.trie.model.FlattenedLeaf;
import net.consensys.shomei.trie.model.LeafOpening;
import net.consensys.shomei.trie.node.EmptyLeafNode;
import net.consensys.shomei.trie.path.PathResolver;
import net.consensys.shomei.trie.proof.EmptyTrace;
import net.consensys.shomei.trie.proof.Proof;
import net.consensys.shomei.trie.proof.Trace;
import net.consensys.shomei.trie.proof.builder.DeletionTraceBuilder;
import net.consensys.shomei.trie.proof.builder.InsertionTraceBuilder;
import net.consensys.shomei.trie.proof.builder.ReadTraceBuilder;
import net.consensys.shomei.trie.proof.builder.ReadZeroTraceBuilder;
import net.consensys.shomei.trie.proof.builder.UpdateTraceBuilder;
import net.consensys.shomei.trie.storage.InMemoryRepository;
import net.consensys.shomei.trie.storage.TrieRepository;
import net.consensys.shomei.trie.storage.TrieRepository.Range;
import net.consensys.shomei.util.bytes.MimcSafeBytes;
import net.consensys.zkevm.HashProvider;

import java.util.Collections;
import java.util.List;
import java.util.Optional;

import org.apache.tuweni.bytes.Bytes;
import org.apache.tuweni.bytes.Bytes32;
import org.hyperledger.besu.datatypes.Hash;
import org.hyperledger.besu.ethereum.trie.Node;
import org.hyperledger.besu.ethereum.trie.NodeUpdater;

/**
 * The ZKTrie class represents a zero-knowledge Merkle trie. It provides methods for storing,
 * retrieving, and manipulating data in the trie. The ZKTrie implements the Trie interface and uses
 * a Merkle tree structure for efficient storage and retrieval.
 */
public class ZKTrie {

  public static final ZKTrie EMPTY_TRIE = generateEmptyTrie();

  public static final Hash DEFAULT_TRIE_ROOT =
      Hash.wrap(createTrie(new InMemoryRepository()).getTopRootHash());

  private static final int ZK_TRIE_DEPTH = 40;

  private final PathResolver pathResolver;
  private final StoredSparseMerkleTrie state;
  private final TrieRepository worldStateStorage;

  private final TrieRepository.TrieUpdater updater;

  public TrieRepository getWorldStateStorage() {
    return worldStateStorage;
  }

  /**
   * Creates a new ZK trie.
   *
   * @param rootHash the root hash of the trie
   * @param worldStateStorage the storage used to store the trie
   * @return the created ZK trie
   */
  private ZKTrie(final Bytes32 rootHash, final TrieRepository worldStateStorage) {
    this.worldStateStorage = worldStateStorage;
    this.updater = worldStateStorage.updater();
    this.state = new StoredSparseMerkleTrie(worldStateStorage::getTrieNode, rootHash, b -> b);
    this.pathResolver = new PathResolver(ZK_TRIE_DEPTH, state);
  }

  public static ZKTrie generateEmptyTrie() {
    final InMemoryRepository inMemoryStorage =
        new InMemoryRepository() {
          @Override
          public Optional<Bytes> getTrieNode(final Bytes location, final Bytes nodeHash) {
            return Optional.ofNullable(super.getTrieNodeStorage().get(nodeHash));
            // In a sparse Merkle trie, the hash value of a parent node is computed based on the
            // hashes of its children nodes.
            // so the hash value of a parent node at each level will be the same as long as its
            // children remain unchanged.
            // this ensures the consistency of the hash values within each level.
            // for that nodes are saved by hash in order to not have to fill all the trie during
            // the init step
          }

          @Override
          public void putTrieNode(final Bytes location, final Bytes nodeHash, final Bytes value) {
            super.getTrieNodeStorage().put(nodeHash, value);
          }
        };
    return new ZKTrie(initWorldState(inMemoryStorage::putTrieNode).getHash(), inMemoryStorage);
  }

  public static ZKTrie createTrie(final TrieRepository worldStateStorage) {
    final ZKTrie trie = new ZKTrie(EMPTY_TRIE.getTopRootHash(), worldStateStorage);
    trie.setHeadAndTail();
    return trie;
  }

  public static ZKTrie loadTrie(final Bytes32 rootHash, final TrieRepository worldStateStorage) {
    return new ZKTrie(rootHash, worldStateStorage);
  }

  /**
   * Fills the sparse Merkle trie by creating a single node on each level with two children per
   * level. Each level is filled with branch nodes, except for the bottom level with empty leaf
   * nodes.
   *
   * <p>This approach simplifies the population process by creating a balanced trie structure with a
   * fixed number of nodes on each level. Each level (except the bottom level) has two children,
   * which are empty branch nodes. The bottom level has empty leaf nodes.
   *
   * <p>Algorithm: 1. Start with an empty trie. 2. Create leaf nodes at the bottom level. 3. For
   * each level of the trie (starting from the bottom level and moving upwards): - Create a parent
   * node with the leaf/branch nodes of the current level as children. - Insert the parent node into
   * the trie.
   */
  private static Node<Bytes> initWorldState(final NodeUpdater nodeUpdater) {
    // if empty we need to fill the sparse trie with zero leaves
    final StoredNodeFactory nodeFactory =
        new StoredNodeFactory((location, hash) -> Optional.empty(), a -> a);
    Node<Bytes> defaultNode = EmptyLeafNode.instance();
    for (int i = 0; i < ZK_TRIE_DEPTH; i++) {
      nodeUpdater.store(null, defaultNode.getHash(), defaultNode.getEncodedBytes());
      defaultNode = nodeFactory.createBranch(Collections.nCopies(2, defaultNode), Optional.empty());
    }
    nodeUpdater.store(null, defaultNode.getHash(), defaultNode.getEncodedBytes());

    // create root node
    defaultNode =
        nodeFactory.createBranch(List.of(EmptyLeafNode.instance(), defaultNode), Optional.empty());

    nodeUpdater.store(null, defaultNode.getHash(), defaultNode.getEncodedBytes());

    return defaultNode;
  }

  public void setHeadAndTail() {
    // head
    final Long headIndex = pathResolver.getNextFreeLeafNodeIndex();
    updater.putFlatLeaf(LeafOpening.HEAD.getHkey(), FlattenedLeaf.HEAD);
    state.put(pathResolver.getLeafPath(headIndex), LeafOpening.HEAD.getEncodesBytes());
    pathResolver.incrementNextFreeLeafNodeIndex();
    // tail
    final Long tailIndex = pathResolver.getNextFreeLeafNodeIndex();
    updater.putFlatLeaf(LeafOpening.TAIL.getHkey(), FlattenedLeaf.TAIL);
    state.put(pathResolver.getLeafPath(tailIndex), LeafOpening.TAIL.getEncodesBytes());
    pathResolver.incrementNextFreeLeafNodeIndex();
  }

  public Node<Bytes> getSubRootNode() {
    return state.getNode(pathResolver.geRootPath());
  }

  public Node<Bytes> getTopRootNode() {
    return state.root;
  }

  public Bytes32 getSubRootHash() {
    return getSubRootNode().getHash();
  }

  public Bytes32 getTopRootHash() {
    return state.getRootHash();
  }

  public long getNextFreeNode() {
    return pathResolver.getNextFreeLeafNodeIndex();
  }

  public Optional<Long> getLeafIndex(final Hash hkey) {
    return worldStateStorage.getFlatLeaf(hkey).map(FlattenedLeaf::leafIndex);
  }

  public Optional<Bytes> get(final Hash hkey) {
    return worldStateStorage
        .getFlatLeaf(hkey)
        .map(FlattenedLeaf::leafIndex)
        .map(pathResolver::getLeafPath)
        .flatMap(this::get);
  }

  public Optional<GetAndProve> getMerkleProof(final Hash hkey) {
    return worldStateStorage
        .getFlatLeaf(hkey)
        .map(FlattenedLeaf::leafIndex)
        .map(pathResolver::getLeafPath)
        .map(this::getMerkleProof);
  }

  public Trace readAndProve(final Hash hkey, final MimcSafeBytes<? extends Bytes> key) {
    // GET the openings HKEY-,  hash(k) , HKEY+
    final Range nearestKeys = worldStateStorage.getNearestKeys(hkey);
    // CHECK if hash(k) exist
    if (nearestKeys.getCenterNodeKey().isEmpty()) {
      // INIT trace
      final ReadZeroTraceBuilder readZeroTrace =
          ReadZeroTraceBuilder.aReadZeroTrace().withSubRoot(getSubRootNode());

      // GET path of HKey-
      final Bytes leftLeafPath =
          pathResolver.getLeafPath(nearestKeys.getLeftNodeValue().leafIndex());
      // GET path of HKey+
      final Bytes rightLeafPath =
          pathResolver.getLeafPath(nearestKeys.getRightNodeValue().leafIndex());

      final GetAndProve leftData = getMerkleProof(leftLeafPath);
      final GetAndProve rightData = getMerkleProof(rightLeafPath);

      return readZeroTrace
          .withKey(key.getOriginalUnsafeValue())
          .withNextFreeNode(pathResolver.getNextFreeLeafNodeIndex())
          .withLeftLeaf(leftData.nodeValue().map(LeafOpening::readFrom).orElseThrow())
          .withRightLeaf(rightData.nodeValue().map(LeafOpening::readFrom).orElseThrow())
          .withLeftProof(new Proof(nearestKeys.getLeftNodeValue().leafIndex(), leftData.proof()))
          .withRightProof(new Proof(nearestKeys.getRightNodeValue().leafIndex(), rightData.proof()))
          .build();

    } else {
      // INIT trace
      final ReadTraceBuilder readTrace =
          ReadTraceBuilder.aReadTrace().withSubRoot(getSubRootNode());

      final FlattenedLeaf currentFlatLeafValue = nearestKeys.getCenterNodeValue().orElseThrow();

      // GET path of hash(k)
      final Bytes leafPath = pathResolver.getLeafPath(currentFlatLeafValue.leafIndex());
      // READ hash(k)
      final GetAndProve data = getMerkleProof(leafPath);

      return readTrace
          .withKey(key.getOriginalUnsafeValue())
          .withNextFreeNode(pathResolver.getNextFreeLeafNodeIndex())
          .withValue(currentFlatLeafValue.leafValue())
          .withLeaf(data.nodeValue().map(LeafOpening::readFrom).orElseThrow())
          .withProof(new Proof(currentFlatLeafValue.leafIndex(), data.proof()))
          .build();
    }
  }

  private Optional<Bytes> get(final Bytes path) {
    return state.get(path);
  }

  private GetAndProve getMerkleProof(final Bytes path) {
    return state.getAndProve(path);
  }

  public Trace putAndProve(
      final Hash hKey,
      final MimcSafeBytes<? extends Bytes> key,
      final MimcSafeBytes<? extends Bytes> newValue) {
    checkArgument(hKey.size() == Bytes32.SIZE);

    // GET the openings HKEY-,  hash(k) , HKEY+
    final Range nearestKeys = worldStateStorage.getNearestKeys(hKey);

    // CHECK if hash(k) exist
    if (nearestKeys.getCenterNodeKey().isEmpty()) {

      // INIT trace
      final InsertionTraceBuilder insertionTrace =
          InsertionTraceBuilder.anInsertionTrace().withOldSubRoot(getSubRootNode());

      // GET path of HKey-
      final Bytes leftLeafPath =
          pathResolver.getLeafPath(nearestKeys.getLeftNodeValue().leafIndex());
      // GET path of HKey+
      final Bytes rightLeafPath =
          pathResolver.getLeafPath(nearestKeys.getRightNodeValue().leafIndex());

      // FIND next free node
      final long nextFreeNode = pathResolver.getNextFreeLeafNodeIndex();

      // UPDATE HKey- with hash(k) for next
      final LeafOpening priorLeftLeaf = get(leftLeafPath).map(LeafOpening::readFrom).orElseThrow();

      final LeafOpening newLeftLeaf = new LeafOpening(priorLeftLeaf);
      newLeftLeaf.setNextLeaf(nextFreeNode);

      final List<Node<Bytes>> leftSiblings =
          state.putAndProve(leftLeafPath, newLeftLeaf.getEncodesBytes());

      // PUT hash(k) with HKey- for Prev and HKey+ for next
      final Bytes leafPathToAdd = pathResolver.getLeafPath(nextFreeNode);
      updater.putFlatLeaf(hKey, new FlattenedLeaf(nextFreeNode, newValue.getOriginalUnsafeValue()));
      final LeafOpening newLeafValue =
          new LeafOpening(
              nearestKeys.getLeftNodeValue().leafIndex(),
              nearestKeys.getRightNodeValue().leafIndex(),
              hKey,
              HashProvider.mimc(newValue));

      final List<Node<Bytes>> centerSiblings =
          state.putAndProve(leafPathToAdd, newLeafValue.getEncodesBytes());

      // UPDATE HKey+ with hash(k) for prev
      final LeafOpening priorRightLeaf =
          get(rightLeafPath).map(LeafOpening::readFrom).orElseThrow();
      final LeafOpening newRightLeaf = new LeafOpening(priorRightLeaf);
      newRightLeaf.setPrevLeaf(nextFreeNode);

      final List<Node<Bytes>> rightSiblings =
          state.putAndProve(rightLeafPath, newRightLeaf.getEncodesBytes());

      // UPDATE next free node
      pathResolver.incrementNextFreeLeafNodeIndex();

      return insertionTrace
          .withKey(key.getOriginalUnsafeValue())
          .withValue(newValue.getOriginalUnsafeValue())
          .withPriorLeftLeaf(priorLeftLeaf)
          .withPriorRightLeaf(priorRightLeaf)
          .withLeftProof(new Proof(nearestKeys.getLeftNodeValue().leafIndex(), leftSiblings))
          .withNewProof(new Proof(nextFreeNode, centerSiblings))
          .withRightProof(new Proof(nearestKeys.getRightNodeValue().leafIndex(), rightSiblings))
          .withNewNextFreeNode(pathResolver.getNextFreeLeafNodeIndex())
          .withNewSubRoot(getSubRootNode())
          .build();

    } else {

      // INIT trace
      final UpdateTraceBuilder updateTrace =
          UpdateTraceBuilder.anUpdateTrace().withOldSubRoot(getSubRootNode());

      final FlattenedLeaf currentFlatLeafValue = nearestKeys.getCenterNodeValue().orElseThrow();

      final Bytes leafPathToUpdate = pathResolver.getLeafPath(currentFlatLeafValue.leafIndex());
      updater.putFlatLeaf(
          hKey,
          new FlattenedLeaf(currentFlatLeafValue.leafIndex(), newValue.getOriginalUnsafeValue()));

      // RETRIEVE OLD VALUE
      final LeafOpening priorUpdatedLeaf =
          get(leafPathToUpdate).map(LeafOpening::readFrom).orElseThrow();
      final LeafOpening newUpdatedLeaf = new LeafOpening(priorUpdatedLeaf);
      newUpdatedLeaf.setHval(HashProvider.mimc(newValue));

      final List<Node<Bytes>> siblings =
          state.putAndProve(leafPathToUpdate, newUpdatedLeaf.getEncodesBytes());

      return updateTrace
          .withKey(key.getOriginalUnsafeValue())
          .withOldValue(currentFlatLeafValue.leafValue())
          .withNewValue(newValue.getOriginalUnsafeValue())
          .withPriorUpdatedLeaf(priorUpdatedLeaf)
          .withProof(new Proof(currentFlatLeafValue.leafIndex(), siblings))
          .withNewNextFreeNode(pathResolver.getNextFreeLeafNodeIndex())
          .withNewSubRoot(getSubRootNode())
          .build();
    }
  }

  public Trace removeAndProve(final Hash hkey, final MimcSafeBytes<? extends Bytes> key) {
    checkArgument(hkey.size() == Bytes32.SIZE);

    // GET the openings HKEY-,  hash(k) , HKEY+
    final Range nearestKeys = worldStateStorage.getNearestKeys(hkey);

    // CHECK if hash(k) exist
    if (nearestKeys.getCenterNode().isPresent()) {

      // INIT trace
      final DeletionTraceBuilder deleteTrace =
          DeletionTraceBuilder.aDeletionTrace().withOldSubRoot(getSubRootNode());

      final Long leftLeafIndex = nearestKeys.getLeftNodeValue().leafIndex();
      final Long rightLeafIndex = nearestKeys.getRightNodeValue().leafIndex();

      // UPDATE HKey- with HKey+ for next
      final Bytes leftLeafPath = pathResolver.getLeafPath(leftLeafIndex);
      final LeafOpening priorLeftLeaf = get(leftLeafPath).map(LeafOpening::readFrom).orElseThrow();
      final LeafOpening newLeftLeaf = new LeafOpening(priorLeftLeaf);
      newLeftLeaf.setNextLeaf(rightLeafIndex);

      final List<Node<Bytes>> leftSiblings =
          state.putAndProve(leftLeafPath, newLeftLeaf.getEncodesBytes());

      // REMOVE hash(k)
      final FlattenedLeaf currentFlatLeafValue = nearestKeys.getCenterNodeValue().orElseThrow();
      final Bytes leafPathToDelete = pathResolver.getLeafPath(currentFlatLeafValue.leafIndex());
      final LeafOpening priorDeletedLeaf =
          get(leafPathToDelete).map(LeafOpening::readFrom).orElseThrow();
      updater.removeFlatLeafValue(hkey);
      final List<Node<Bytes>> centerSiblings = state.removeAndProve(leafPathToDelete);

      // UPDATE HKey+ with HKey- for prev
      final Bytes rightLeafPath = pathResolver.getLeafPath(rightLeafIndex);
      final LeafOpening priorRightLeaf =
          get(rightLeafPath).map(LeafOpening::readFrom).orElseThrow();
      final LeafOpening newRightLeaf = new LeafOpening(priorRightLeaf);
      newRightLeaf.setPrevLeaf(leftLeafIndex);

      final List<Node<Bytes>> rightSiblings =
          state.putAndProve(rightLeafPath, newRightLeaf.getEncodesBytes());

      return deleteTrace
          .withKey(key.getOriginalUnsafeValue())
          .withDeletedValue(currentFlatLeafValue.leafValue())
          .withPriorLeftLeaf(priorLeftLeaf)
          .withPriorDeletedLeaf(priorDeletedLeaf)
          .withPriorRightLeaf(priorRightLeaf)
          .withLeftProof(new Proof(nearestKeys.getLeftNodeValue().leafIndex(), leftSiblings))
          .withDeletedProof(
              new Proof(nearestKeys.getCenterNodeValue().orElseThrow().leafIndex(), centerSiblings))
          .withRightProof(new Proof(nearestKeys.getRightNodeValue().leafIndex(), rightSiblings))
          .withNewNextFreeNode(pathResolver.getNextFreeLeafNodeIndex())
          .withNewSubRoot(getSubRootNode())
          .build();
    }

    return new EmptyTrace();
  }

  public void decrementNextFreeNode() {
    pathResolver.decrementNextFreeLeafNodeIndex();
  }

  public void commit() {
    state.commit(updater::putTrieNode);
  }
}
